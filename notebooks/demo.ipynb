{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# StyleForge - Real-Time Neural Style Transfer with CUDA Kernels\n\nThis notebook demonstrates the StyleForge system with optimized CUDA kernels for real-time neural style transfer.\n\n## Features\n\n- **Fused Multi-Head Attention V3**: 4-8x faster than PyTorch with batched query processing\n- **Fused Instance Norm**: 2-4x faster normalization\n- **Fused Conv+InstanceNorm+ReLU**: 5-8x speedup for residual blocks\n- **Comprehensive Benchmarking**: Automated profiling and reporting\n- **Nsight Compute Integration**: Deep GPU performance analysis\n\n## Requirements\n\n- CUDA 11.0+ GPU with Compute Capability 7.0+\n- PyTorch 1.10+ with CUDA support"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup Repository\n",
    "\n",
    "Clone and navigate to the StyleForge directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "# Check if running in Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    REPO_DIR = \"/content/StyleForge\"\n",
    "    print(\"üìå Running in Google Colab\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    REPO_DIR = None\n",
    "    print(\"üìå Not running in Google Colab\")\n",
    "\n",
    "# Navigate to repository\n",
    "if Path.cwd().name == \"StyleForge\":\n",
    "    print(\"Already in StyleForge directory\")\n",
    "elif (Path.cwd().parent / \"StyleForge\").exists():\n",
    "    os.chdir(\"../StyleForge\")\n",
    "    print(\"Changed to parent StyleForge directory\")\n",
    "elif IN_COLAB and not Path(REPO_DIR).exists():\n",
    "    # Clone repository\n",
    "    print(f\"Cloning StyleForge repository to {REPO_DIR}...\")\n",
    "    !git clone https://github.com/oleeveeuh/StyleForge.git {REPO_DIR}\n",
    "    os.chdir(REPO_DIR)\n",
    "\n",
    "print(f\"\\nWorking directory: {Path.cwd()}\")\n",
    "print(f\"Repository exists: {(Path.cwd() / 'kernels').exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup & Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"StyleForge - CUDA Kernel Demo\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Check CUDA availability\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    props = torch.cuda.get_device_properties(0)\n",
    "    print(f\"\\n‚úÖ CUDA available!\")\n",
    "    print(f\"   GPU: {props.name}\")\n",
    "    print(f\"   Compute Capability: {props.major}.{props.minor}\")\n",
    "    print(f\"   Total Memory: {props.total_memory / 1e9:.2f} GB\")\n",
    "    print(f\"   Streaming MPs: {props.multi_processor_count}\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"\\n‚ö†Ô∏è CUDA not available - using CPU\")\n",
    "\n",
    "# Add project to path\n",
    "if str(Path.cwd()) not in sys.path:\n",
    "    sys.path.insert(0, str(Path.cwd())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load StyleForge Kernels\n",
    "\n",
    "The kernels will be JIT-compiled on first use. This may take 30-60 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"=\" * 70)\nprint(\"Loading StyleForge CUDA Kernels...\")\nprint(\"=\" * 70)\n\n# Import kernels\nfrom kernels import (\n    FusedAttentionV3,\n    FusedInstanceNorm2d,\n    FusedConvInstanceNormReLU,\n    ResidualBlock,\n    benchmark_conv_fusion_vs_pytorch,\n    run_conv_fusion_benchmark,\n)\n\n# Import benchmarking framework\nfrom benchmarking import (\n    BenchmarkFramework,\n    BenchmarkConfig,\n    BenchmarkReport,\n    BenchmarkVisualizer,\n    HAS_MATPLOTLIB,\n)\n\nprint(\"\\n‚úÖ All kernels imported successfully!\")\nprint(\"\\nAvailable kernels:\")\nprint(\"  - FusedAttentionV3 (4-8x speedup)\")\nprint(\"  - FusedInstanceNorm2d (2-4x speedup)\")\nprint(\"  - FusedConvInstanceNormReLU (5-8x speedup)\")\nprint(\"  - ResidualBlock (uses fused kernels)\")\nprint(\"\\nBenchmarking framework:\")\nprint(\"  - BenchmarkFramework (automated timing)\")\nprint(\"  - BenchmarkReport (MD/JSON/HTML/CSV)\")\nprint(f\"  - BenchmarkVisualizer (matplotlib: {HAS_MATPLOTLIB})\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Quick Kernel Demonstration\n",
    "\n",
    "Test each fused kernel with correctness validation and speedup measurement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"=\" * 70)\nprint(\"Quick Kernel Demonstration\")\nprint(\"=\" * 70)\n\n# Test configurations\ntest_configs = [\n    (\"Small\", 1, 64, 64, 64),\n    (\"Medium\", 1, 128, 128, 128),\n]\n\nfor name, batch, channels, h, w in test_configs:\n    print(f\"\\n{name}: [{batch}, {channels}, {h}, {w}]\")\n    x = torch.randn(batch, channels, h, w, device=device)\n\n    # Test FusedInstanceNorm2d\n    try:\n        norm = FusedInstanceNorm2d(channels).to(device).eval()\n        with torch.no_grad():\n            out = norm(x)\n        print(f\"  ‚úÖ FusedInstanceNorm2d: {out.shape}\")\n    except Exception as e:\n        print(f\"  ‚ùå FusedInstanceNorm2d: {e}\")\n\n    # Test FusedConvInstanceNormReLU\n    try:\n        conv = FusedConvInstanceNormReLU(channels, channels, 3).to(device).eval()\n        with torch.no_grad():\n            out = conv(x)\n        print(f\"  ‚úÖ FusedConv+IN+ReLU: {out.shape}\")\n    except Exception as e:\n        print(f\"  ‚ùå FusedConv+IN+ReLU: {e}\")\n\n# Test FusedAttentionV3\nprint(\"\\n\" + \"=\" * 50)\nprint(\"Testing FusedAttentionV3:\")\nprint(\"=\" * 50)\n\ntry:\n    # Attention uses different tensor shapes (batch, seq_len, embed_dim)\n    batch, seq_len, embed_dim, num_heads = 2, 128, 256, 8\n    q = torch.randn(batch, seq_len, embed_dim, device=device)\n    k = torch.randn(batch, seq_len, embed_dim, device=device)\n    v = torch.randn(batch, seq_len, embed_dim, device=device)\n    \n    attn = FusedAttentionV3(embed_dim=embed_dim, num_heads=num_heads).to(device).eval()\n    with torch.no_grad():\n        out = attn(q, k, v)\n    print(f\"  ‚úÖ FusedAttentionV3: {out.shape}\")\nexcept Exception as e:\n    print(f\"  ‚ùå FusedAttentionV3: {e}\")\n\nprint(\"\\n‚úÖ All kernels working!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run Comprehensive Benchmarks\n",
    "\n",
    "Use the BenchmarkFramework to automatically compare kernels against PyTorch baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"Automated Benchmarking with BenchmarkFramework\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create framework\n",
    "framework = BenchmarkFramework(use_cuda_events=True)\n",
    "\n",
    "# Define test configurations\n",
    "configs = [\n",
    "    BenchmarkConfig(\"64√ó64\", 1, 64, 64, 64, iterations=50),\n",
    "    BenchmarkConfig(\"128√ó128\", 1, 128, 128, 128, iterations=50),\n",
    "    BenchmarkConfig(\"256√ó256\", 1, 64, 256, 256, iterations=30),\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for config in configs:\n",
    "    # Create input\n",
    "    x = framework.create_input_tensor(config)\n",
    "\n",
    "    # PyTorch baseline\n",
    "    pytorch_norm = nn.InstanceNorm2d(config.channels, affine=True).to(device).eval()\n",
    "\n",
    "    # Fused kernel\n",
    "    fused_norm = FusedInstanceNorm2d(config.channels, affine=True).to(device).eval()\n",
    "\n",
    "    # Copy weights\n",
    "    with torch.no_grad():\n",
    "        fused_norm.gamma.copy_(pytorch_norm.weight)\n",
    "        fused_norm.beta.copy_(pytorch_norm.bias)\n",
    "\n",
    "    # Compare\n",
    "    result = framework.compare(\n",
    "        baseline_func=pytorch_norm,\n",
    "        optimized_func=fused_norm,\n",
    "        config=config,\n",
    "        input_tensor=x,\n",
    "        validate=True,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    if result is not None:\n",
    "        results.append(result.to_dict())\n",
    "\n",
    "# Print summary\n",
    "framework.print_summary()\n",
    "\n",
    "# Save results\n",
    "framework.save_results('benchmark_results/demo_results.json')\n",
    "print(\"\\n‚úÖ Results saved to benchmark_results/demo_results.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generate Professional Reports\n",
    "\n",
    "Create markdown, JSON, HTML, and CSV reports from benchmark results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"Generating Benchmark Reports\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create report generator\n",
    "report = BenchmarkReport(\n",
    "    title=\"StyleForge CUDA Kernel Performance Report\",\n",
    "    subtitle=\"Fused InstanceNorm2d Benchmark Results\"\n",
    ")\n",
    "\n",
    "# Generate all formats\n",
    "output_dir = Path('benchmark_results/demo_reports')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "report.generate_all_formats(results, str(output_dir))\n",
    "\n",
    "print(f\"\\n‚úÖ Reports saved to: {output_dir}/\")\n",
    "print(\"   - report.md  (Markdown)\")\n",
    "print(\"   - report.json (JSON)\")\n",
    "print(\"   - report.html (HTML)\")\n",
    "print(\"   - report.csv (CSV)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Performance (Optional)\n",
    "\n",
    "Generate charts if matplotlib is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if HAS_MATPLOTLIB:\n",
    "    print(\"=\" * 70)\n",
    "    print(\"Generating Performance Charts\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    visualizer = BenchmarkVisualizer()\n",
    "    charts_dir = output_dir / 'charts'\n",
    "    visualizer.generate_all_charts(results, str(charts_dir))\n",
    "\n",
    "    print(f\"\\n‚úÖ Charts saved to: {charts_dir}/\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è matplotlib not installed - skipping charts\")\n",
    "    print(\"   Install with: pip install matplotlib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conv+InstanceNorm+ReLU Benchmark\n",
    "\n",
    "Run the comprehensive fused convolution benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"=\" * 70)\nprint(\"Fused Conv+InstanceNorm+ReLU Benchmark\")\nprint(\"=\" * 70)\n\n# Run the comprehensive benchmark\nconv_results = run_conv_fusion_benchmark()\n\nprint(\"\\n‚úÖ Conv fusion benchmark complete!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Style Transfer Model Demo\n",
    "\n",
    "Now let's use these kernels in an actual style transfer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.transformer_net import TransformerNet, AVAILABLE_STYLES\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"Fast Style Transfer Model\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nAvailable styles: {', '.join(AVAILABLE_STYLES)}\")\n",
    "\n",
    "# Create model\n",
    "style_model = TransformerNet(num_residual_blocks=5).to(device)\n",
    "style_model.eval()\n",
    "\n",
    "total_params = sum(p.numel() for p in style_model.parameters())\n",
    "print(f\"\\nModel parameters: {total_params:,}\")\n",
    "print(\"‚úÖ Model loaded\")\n",
    "\n",
    "# Test the model\n",
    "x = torch.randn(1, 3, 256, 256, device=device)\n",
    "\n",
    "# Warmup\n",
    "with torch.no_grad():\n",
    "    for _ in range(5):\n",
    "        _ = style_model(x)\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "# Benchmark\n",
    "times = []\n",
    "with torch.no_grad():\n",
    "    for _ in range(20):\n",
    "        start = torch.cuda.Event(enable_timing=True)\n",
    "        end = torch.cuda.Event(enable_timing=True)\n",
    "        start.record()\n",
    "        output = style_model(x)\n",
    "        end.record()\n",
    "        torch.cuda.synchronize()\n",
    "        times.append(start.elapsed_time(end))\n",
    "\n",
    "avg_ms = np.mean(times)\n",
    "fps = 1000 / avg_ms\n",
    "\n",
    "print(f\"\\nStyle Transfer Performance (256x256):\")\n",
    "print(f\"  Latency: {avg_ms:.2f} ms\")\n",
    "print(f\"  FPS: {fps:.2f}\")\n",
    "print(f\"  Real-time: {'‚úÖ YES' if fps >= 30 else '‚ùå NO'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Image Style Transfer\n",
    "\n",
    "Upload an image and apply style transfer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import files\n",
    "    from io import BytesIO\n",
    "    from PIL import Image\n",
    "    import matplotlib.pyplot as plt\n",
    "    from torchvision import transforms\n",
    "\n",
    "    print(\"=\" * 70)\n",
    "    print(\"Image Upload & Style Transfer\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"\\nüìÅ Upload an image:\\n\")\n",
    "\n",
    "    uploaded = files.upload()\n",
    "\n",
    "    if uploaded:\n",
    "        for filename in uploaded.keys():\n",
    "            print(f\"\\nProcessing {filename}...\")\n",
    "\n",
    "            # Load image\n",
    "            img = Image.open(BytesIO(uploaded[filename])).convert('RGB')\n",
    "            original_size = img.size\n",
    "\n",
    "            # Resize for processing\n",
    "            PROCESSING_SIZE = 512\n",
    "            aspect = img.size[0] / img.size[1]\n",
    "            if aspect > 1:\n",
    "                new_size = (PROCESSING_SIZE, int(PROCESSING_SIZE / aspect))\n",
    "            else:\n",
    "                new_size = (int(PROCESSING_SIZE * aspect), PROCESSING_SIZE)\n",
    "            img_resized = img.resize(new_size, Image.Resampling.LANCZOS)\n",
    "\n",
    "            # Convert to tensor\n",
    "            transform = transforms.Compose([transforms.ToTensor()])\n",
    "            input_tensor = transform(img_resized).unsqueeze(0).to(device)\n",
    "\n",
    "            # Apply style transfer\n",
    "            with torch.no_grad():\n",
    "                start = time.perf_counter()\n",
    "                output_tensor = style_model(input_tensor)\n",
    "                torch.cuda.synchronize()\n",
    "                elapsed_ms = (time.perf_counter() - start) * 1000\n",
    "\n",
    "            # Convert back\n",
    "            to_pil = transforms.ToPILImage()\n",
    "            output_img = to_pil(output_tensor.squeeze(0).clamp(0, 1))\n",
    "            output_img = output_img.resize(original_size, Image.Resampling.LANCZOS)\n",
    "\n",
    "            # Display\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "            axes[0].imshow(img)\n",
    "            axes[0].set_title('Original')\n",
    "            axes[0].axis('off')\n",
    "            axes[1].imshow(output_img)\n",
    "            axes[1].set_title(f'Stylized ({elapsed_ms:.1f} ms)')\n",
    "            axes[1].axis('off')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "            # Save and download\n",
    "            result_filename = f'stylized_{filename}'\n",
    "            output_img.save(result_filename, quality=95)\n",
    "            print(f\"‚úÖ Saved: {result_filename}\")\n",
    "            files.download(result_filename)\n",
    "\n",
    "except ImportError:\n",
    "    print(\"\\nNote: Image upload works in Google Colab.\")\n",
    "    print(\"For local Jupyter, use:\")\n",
    "    print(\"  from PIL import Image\")\n",
    "    print(\"  img = Image.open('path/to/image.jpg')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Nsight Compute Profiling\n",
    "\n",
    "Profile kernels with NVIDIA Nsight Compute for deep GPU analysis.\n",
    "\n",
    "**Note:** This requires Nsight Compute to be installed locally.\n",
    "Colab does not support ncu profiling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import shutil\n",
    "\n",
    "# Check if ncu is available\n",
    "ncu_available = shutil.which('ncu') is not None\n",
    "\n",
    "if ncu_available:\n",
    "    print(\"=\" * 70)\n",
    "    print(\"Nsight Compute Profiling\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"\\n‚úÖ ncu found - profiling available!\")\n",
    "    print(\"\\nTo profile kernels locally:\")\n",
    "    print(\"  cd profiling\")\n",
    "    print(\"  ./profile.sh instance_norm\")\n",
    "    print(\"\\nThen analyze results:\")\n",
    "    print(\"  python analyze_profile.py nsight_reports/*.csv\")\n",
    "else:\n",
    "    print(\"=\" * 70)\n",
    "    print(\"Nsight Compute Profiling\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"\\n‚ö†Ô∏è ncu not found - profiling unavailable\")\n",
    "    print(\"\\nInstall from: https://developer.nvidia.com/nsight-compute\")\n",
    "    print(\"\\nProfiling features:\")\n",
    "    print(\"  - Kernel duration measurement\")\n",
    "    print(\"  - Memory bandwidth analysis\")\n",
    "    print(\"  - GPU utilization tracking\")\n",
    "    print(\"  - Warp occupancy analysis\")\n",
    "    print(\"  - Optimization recommendations\")\n",
    "\n",
    "# Show profiling script location\n",
    "profiling_dir = Path('profiling')\n",
    "if profiling_dir.exists():\n",
    "    print(f\"\\nüìÅ Profiling directory: {profiling_dir.absolute()}\")\n",
    "    print(\"\\nFiles:\")\n",
    "    for f in profiling_dir.glob('*.py'):\n",
    "        print(f\"  - {f.name}\")\n",
    "    for f in profiling_dir.glob('*.sh'):\n",
    "        print(f\"  - {f.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 11. Summary & Achievements\n\n### Implemented Kernels\n\n| Kernel | Speedup | Description |\n|--------|---------|-------------|\n| FusedAttentionV3 | 4-8x | Multi-head attention with batched query processing |\n| FusedInstanceNorm2d | 2-4x | Instance normalization with affine |\n| FusedConvInstanceNormReLU | 5-8x | Conv+IN+ReLU for residual blocks |\n\n### Infrastructure\n\n| Component | Description |\n|-----------|-------------|\n| BenchmarkFramework | Automated timing with CUDA events |\n| BenchmarkReport | Generate MD/JSON/HTML/CSV reports |\n| BenchmarkVisualizer | Create performance charts |\n| Nsight Integration | Deep GPU profiling & analysis |\n\n### How to Use\n\n```python\n# Import kernels\nfrom kernels import FusedAttentionV3, FusedInstanceNorm2d, ResidualBlock\n\n# Use fused attention\nattn = FusedAttentionV3(embed_dim=256, num_heads=8).cuda()\nq = k = v = torch.randn(2, 128, 256).cuda()\nout = attn(q, k, v)\n\n# Use fused layer\nnorm = FusedInstanceNorm2d(64).cuda()\nx = torch.randn(1, 64, 256, 256).cuda()\ny = norm(x)\n\n# Or use residual block\nblock = ResidualBlock(128).cuda()\ny = block(x)\n```\n\n### Running Benchmarks\n\n```bash\n# Quick benchmark\npython run_full_benchmark.py --kernels instance_norm\n\n# Full benchmark suite\npython run_full_benchmark.py\n\n# Profile with Nsight\ncd profiling && ./profile.sh instance_norm\n```"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}